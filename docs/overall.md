You are helping me build a production-grade AI Research Studio on Google Cloud Platform.
This is a serious engineering project, not a demo.

========================
PROJECT GOAL
========================
Build an AI Research Studio that:

1. Accepts a user question, hypothesis, or draft (with text, equations, code, PDFs, links)
2. Gathers web evidence in a controlled, reproducible way
3. Synthesizes evidence
4. Runs multi-LLM debate (NO web access during debate)
5. Produces aligned, structured output:
   - Text (markdown)
   - Equations (LaTeX, rendered in UI)
   - Code (executable, versioned)
   - Charts (generated by re-running saved code)
6. Allows saving results as reusable artifacts with unique IDs (ART-xxxxx)
7. Supports fresh chats that can rehydrate saved artifacts
8. Supports text search over past inputs/outputs
9. Supports re-running saved analysis code to regenerate charts
10. Supports DOCX and PDF export

========================
MANDATORY ARCHITECTURE
========================
Use this pipeline exactly:

User Question
   ↓
SerpAPI (top 50–100 URLs, deterministic, timestamped)
   ↓
Fetcher service (downloads & cleans page text)
   ↓
Perplexity (SEARCH + SYNTHESIS ONLY)
   ↓
Normalized Evidence Pack (versioned, saved)
   ↓
Debate LLMs (OpenAI / Claude / Groq / Grok)
   ↓   (NO WEB ACCESS HERE)
Referee / Aligned Output
   ↓
Structured blocks (text / equations / code / charts)

Rules:
- Perplexity MUST NOT participate in debate
- Debate LLMs MUST NOT browse the web
- Evidence must be snapshot-based and reproducible

========================
INFRA & DEPLOYMENT CONSTRAINTS
========================
Cloud Provider:
- Google Cloud Platform (GCP)

Infrastructure:
- MUST be created with Terraform
- Services run on Cloud Run
- Async via Pub/Sub
- Firestore for chat memory
- GCS for artifacts, evidence, charts
- BigQuery or equivalent for searchable index

Deployment:
- MUST use: gcloud run deploy --source
- NO Dockerfiles
- NO local Docker
- OS: macOS (Intel)

Secrets:
- Stored in Google Secret Manager
- Terraform only grants access (does NOT recreate secrets)
- API keys already exist except Mathpix and Serp

Source Control:
- Private Git repository
- Git is the source of truth
- Commit to Git separately from deployment
- Deploy manually via gcloud (no CI/CD yet)

========================
PHASED PLAN (LOCKED)
========================

Phase 0 — One-time local & GCP setup (FOUNDATION)
- gcloud authenticated
- ADC enabled
- Terraform installed
- Git + SSH configured
- Private Git repo created
- Local repo initialized and pushed

STATUS: ✅ PHASE 0 COMPLETE (or within final verification)

Phase 1 — Repo scaffolding + first Cloud Run service
- Create repo structure
- Create first service: orchestrator-api
- FastAPI app with:
  - /healthz
  - /chat (stubbed, no LLMs yet)
- Deploy using: gcloud run deploy --source
- NO Terraform resources yet
- NO debate
- NO search
- NO fetcher
Goal: prove Cloud Run + source deploy works

Phase 2 — Terraform infra (minimum viable platform)
- Enable APIs
- Service accounts
- IAM bindings
- Firestore (native)
- Pub/Sub topic + subscription
- GCS buckets

Phase 3 — Chat memory (Firestore)

Phase 4 — Fetcher worker (URL → clean text)

Phase 5 — SerpAPI integration (Top-N URLs)

Phase 6 — Perplexity synthesis (SEARCH ONLY)

Phase 7 — Multi-LLM debate + referee (web-blind)

Phase 8 — Save-to-store artifacts + search

Phase 9 — Code execution + chart regeneration

Phase 10 — DOCX / PDF export

========================
WHERE WE ARE RIGHT NOW
========================
- Phase 0 is complete or just completed
- gcloud works
- Git + SSH works
- Repo exists locally and remotely
- NO application code written yet

========================
PHASE 1 INSTRUCTIONS (DO THIS NEXT)
========================
You must now help me implement **Phase 1 only**.

Phase 1 rules:
- Focus ONLY on:
  - repo scaffolding
  - first Cloud Run service (orchestrator-api)
- Provide:
  1. Folder structure
  2. Exact file contents
  3. gcloud deploy commands
  4. Verification steps (curl / gcloud)
- Use FastAPI (Python)
- Use Cloud Run source-based deploy
- NO Terraform yet
- NO Dockerfiles
- NO LLM APIs yet
- NO Pub/Sub yet
- NO search yet

Before writing code:
- Confirm Phase 1 scope
- Ask me ONLY for:
  - PROJECT_ID
  - REGION (default us-central1 is fine)

Do not skip steps.
Do not redesign the architecture.
Proceed like a staff engineer guiding an implementation.


services/
└── pipeline-runner/
    ├── app/
    │   ├── __init__.py
    │   ├── contracts/
    │   │   ├── __init__.py
    │   │   └── fetcher_contract.py
    │   ├── external/
    │   │   ├── __init__.py
    │   │   └── serpapi.py
    │   ├── pubsub/
    │   │   ├── __init__.py
    │   │   └── publisher.py
    │   ├── routes/
    │   │   ├── __init__.py
    │   │   ├── health.py
    │   │   ├── pubsub_jobs.py
    │   │   └── pubsub_evidence.py
    │   ├── state/
    │   │   ├── __init__.py
    │   │   ├── dedupe.py
    │   │   └── firestore.py
    │   └── storage/
    │       ├── __init__.py
    │       └── gcs.py
    │
    ├── main.py
    ├── Dockerfile
    ├── Procfile
    ├── requirements.txt
    ├── runtime.txt
    └── README.md
